"""
Outlier Detection Module

This module implements pedagogically clear outlier detection methods for spatiotemporal 
trajectory data, aligned with theoretical framework:

- **Graphical**: Box plots for visual outlier identification
- **Statistical**: Z-score and IQR (Interquartile Range)
- **Depth-Based**: Convex Hull Layers
- **Distance-Based**: k-Nearest Neighbors
- **Density-Based**: Local Outlier Factor (LOF)

"An outlier is an observation which deviates so much from the other observations 
as to arouse suspicions that it was generated by a different mechanism." (Hawkins, 1980)

Author: Spatiotemporal Analysis Tool
Date: November 2025
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from scipy import stats
from scipy.spatial import ConvexHull, distance
from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.covariance import EllipticEnvelope
import warnings
warnings.filterwarnings('ignore')

from .common import PLOTLY_CONFIG, render_interactive_chart


# =============================================================================
# FEATURE EXTRACTION
# =============================================================================

def extract_trajectory_features(df, config, obj_id):
    """
    Extract statistical features from a single trajectory for outlier detection.
    
    Parameters:
        df: DataFrame with trajectory data
        config: Configuration name
        obj_id: Object ID
        
    Returns:
        Dictionary of trajectory features
    """
    traj = df[(df['config_source'] == config) & (df['obj'] == obj_id)].sort_values('tst')
    
    if len(traj) < 2:
        return None
    
    # Spatial features
    x_coords = traj['x'].values
    y_coords = traj['y'].values
    
    # Calculate displacements
    dx = np.diff(x_coords)
    dy = np.diff(y_coords)
    distances = np.sqrt(dx**2 + dy**2)
    
    # Temporal features
    times = traj['tst'].values
    dt = np.diff(times)
    dt = dt[dt > 0]  # Remove zero time differences
    
    # Velocities
    velocities = distances / dt if len(dt) > 0 else np.array([0])
    velocities = velocities[np.isfinite(velocities)]
    
    # Accelerations
    if len(velocities) > 1:
        dv = np.diff(velocities)
        accelerations = dv / dt[:-1] if len(dt) > 1 else np.array([0])
        accelerations = accelerations[np.isfinite(accelerations)]
    else:
        accelerations = np.array([0])
    
    features = {
        'config': config,
        'object': obj_id,
        'trajectory_id': f"{config}_obj{obj_id}",
        
        # Basic statistics
        'total_distance': np.sum(distances),
        'duration': times[-1] - times[0],
        'n_points': len(traj),
        
        # Spatial extent
        'x_range': x_coords.max() - x_coords.min(),
        'y_range': y_coords.max() - y_coords.min(),
        'x_mean': x_coords.mean(),
        'y_mean': y_coords.mean(),
        'x_std': x_coords.std(),
        'y_std': y_coords.std(),
        
        # Velocity statistics
        'avg_speed': np.mean(velocities) if len(velocities) > 0 else 0,
        'max_speed': np.max(velocities) if len(velocities) > 0 else 0,
        'std_speed': np.std(velocities) if len(velocities) > 0 else 0,
        
        # Acceleration statistics
        'avg_acceleration': np.mean(np.abs(accelerations)) if len(accelerations) > 0 else 0,
        'max_acceleration': np.max(np.abs(accelerations)) if len(accelerations) > 0 else 0,
        
        # Path complexity
        'sinuosity': np.sum(distances) / np.sqrt((x_coords[-1] - x_coords[0])**2 + 
                                                   (y_coords[-1] - y_coords[0])**2) if np.sqrt((x_coords[-1] - x_coords[0])**2 + (y_coords[-1] - y_coords[0])**2) > 0 else 1,
        
        # Directional change
        'total_turning_angle': calculate_total_turning_angle(x_coords, y_coords),
    }
    
    return features


def calculate_total_turning_angle(x_coords, y_coords):
    """Calculate total turning angle along trajectory."""
    if len(x_coords) < 3:
        return 0
    
    angles = []
    for i in range(1, len(x_coords) - 1):
        v1 = np.array([x_coords[i] - x_coords[i-1], y_coords[i] - y_coords[i-1]])
        v2 = np.array([x_coords[i+1] - x_coords[i], y_coords[i+1] - y_coords[i]])
        
        norm1 = np.linalg.norm(v1)
        norm2 = np.linalg.norm(v2)
        
        if norm1 > 0 and norm2 > 0:
            cos_angle = np.dot(v1, v2) / (norm1 * norm2)
            cos_angle = np.clip(cos_angle, -1, 1)
            angle = np.arccos(cos_angle)
            angles.append(angle)
    
    return np.sum(angles) if angles else 0


# =============================================================================
# STATISTICAL METHODS
# =============================================================================

def detect_outliers_zscore(features_df, feature_cols, threshold=3.0):
    """
    Detect outliers using Z-score method.
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        threshold: Z-score threshold (default: 3.0)
        
    Returns:
        DataFrame with outlier scores and labels
    """
    result_df = features_df.copy()
    
    # Calculate Z-scores for each feature
    z_scores = np.abs(stats.zscore(features_df[feature_cols], nan_policy='omit'))
    
    # A point is an outlier if ANY feature has |z-score| > threshold
    result_df['max_zscore'] = np.max(z_scores, axis=1)
    result_df['is_outlier_zscore'] = result_df['max_zscore'] > threshold
    result_df['outlier_score_zscore'] = result_df['max_zscore'] / threshold
    
    return result_df


def detect_outliers_modified_zscore(features_df, feature_cols, threshold=3.5):
    """
    Detect outliers using Modified Z-score (based on median absolute deviation).
    More robust to outliers than standard Z-score.
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        threshold: Modified Z-score threshold (default: 3.5)
        
    Returns:
        DataFrame with outlier scores and labels
    """
    result_df = features_df.copy()
    
    modified_z_scores = []
    for col in feature_cols:
        median = np.median(features_df[col])
        mad = np.median(np.abs(features_df[col] - median))
        
        if mad == 0:
            modified_z = np.zeros(len(features_df))
        else:
            modified_z = 0.6745 * (features_df[col] - median) / mad
        
        modified_z_scores.append(np.abs(modified_z))
    
    modified_z_scores = np.array(modified_z_scores).T
    
    result_df['max_modified_zscore'] = np.max(modified_z_scores, axis=1)
    result_df['is_outlier_modified_zscore'] = result_df['max_modified_zscore'] > threshold
    result_df['outlier_score_modified_zscore'] = result_df['max_modified_zscore'] / threshold
    
    return result_df


def detect_outliers_iqr(features_df, feature_cols, multiplier=1.5):
    """
    Detect outliers using Interquartile Range (IQR) method.
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        multiplier: IQR multiplier (default: 1.5, use 3.0 for extreme outliers)
        
    Returns:
        DataFrame with outlier labels
    """
    result_df = features_df.copy()
    
    outlier_counts = np.zeros(len(features_df))
    
    for col in feature_cols:
        Q1 = features_df[col].quantile(0.25)
        Q3 = features_df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - multiplier * IQR
        upper_bound = Q3 + multiplier * IQR
        
        outliers = (features_df[col] < lower_bound) | (features_df[col] > upper_bound)
        outlier_counts += outliers.astype(int)
    
    result_df['outlier_feature_count_iqr'] = outlier_counts
    result_df['is_outlier_iqr'] = outlier_counts > 0
    result_df['outlier_score_iqr'] = outlier_counts / len(feature_cols)
    
    return result_df


def detect_outliers_mahalanobis(features_df, feature_cols, threshold=3.0):
    """
    Detect outliers using Mahalanobis distance (accounts for feature correlations).
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        threshold: Chi-square threshold
        
    Returns:
        DataFrame with outlier scores and labels
    """
    result_df = features_df.copy()
    
    X = features_df[feature_cols].values
    
    # Standardize
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Calculate covariance matrix
    cov_matrix = np.cov(X_scaled.T)
    
    try:
        inv_cov_matrix = np.linalg.inv(cov_matrix)
        
        # Calculate Mahalanobis distance for each point
        mahal_distances = []
        mean = np.mean(X_scaled, axis=0)
        
        for i in range(len(X_scaled)):
            diff = X_scaled[i] - mean
            mahal_dist = np.sqrt(diff @ inv_cov_matrix @ diff.T)
            mahal_distances.append(mahal_dist)
        
        result_df['mahalanobis_distance'] = mahal_distances
        result_df['is_outlier_mahalanobis'] = np.array(mahal_distances) > threshold
        result_df['outlier_score_mahalanobis'] = np.array(mahal_distances) / threshold
        
    except np.linalg.LinAlgError:
        # Singular matrix - use alternative
        result_df['mahalanobis_distance'] = 0
        result_df['is_outlier_mahalanobis'] = False
        result_df['outlier_score_mahalanobis'] = 0
    
    return result_df


# =============================================================================
# DEPTH-BASED METHODS
# =============================================================================

def detect_outliers_convex_hull(features_df, feature_cols, depth_threshold=2):
    """
    Detect outliers using convex hull depth method.
    Points in outer layers are considered outliers.
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of 2 feature column names for 2D convex hull
        depth_threshold: Maximum depth to be considered outlier
        
    Returns:
        DataFrame with depth values and outlier labels
    """
    result_df = features_df.copy()
    
    # Use only first 2 features for 2D convex hull
    if len(feature_cols) > 2:
        feature_cols = feature_cols[:2]
    
    points = features_df[feature_cols].values
    n_points = len(points)
    
    depths = np.zeros(n_points)
    remaining_indices = np.arange(n_points)
    current_depth = 1
    
    while len(remaining_indices) > 2:
        try:
            current_points = points[remaining_indices]
            
            if len(current_points) < 3:
                depths[remaining_indices] = current_depth
                break
            
            hull = ConvexHull(current_points)
            hull_point_indices = remaining_indices[hull.vertices]
            
            depths[hull_point_indices] = current_depth
            
            # Remove hull points for next iteration
            mask = np.ones(len(remaining_indices), dtype=bool)
            mask[hull.vertices] = False
            remaining_indices = remaining_indices[mask]
            
            current_depth += 1
            
        except Exception:
            # If convex hull fails, assign remaining points to current depth
            depths[remaining_indices] = current_depth
            break
    
    # Handle remaining points
    if len(remaining_indices) > 0:
        depths[remaining_indices] = current_depth
    
    result_df['convex_hull_depth'] = depths
    result_df['is_outlier_convex_hull'] = depths <= depth_threshold
    result_df['outlier_score_convex_hull'] = 1.0 / depths  # Inverse depth as score
    
    return result_df


# =============================================================================
# DISTANCE-BASED METHODS
# =============================================================================

def detect_outliers_knn_distance(features_df, feature_cols, k=5, threshold_percentile=95):
    """
    Detect outliers based on distance to k-nearest neighbors.
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        k: Number of nearest neighbors
        threshold_percentile: Percentile threshold for outlier detection
        
    Returns:
        DataFrame with distance scores and outlier labels
    """
    result_df = features_df.copy()
    
    X = features_df[feature_cols].values
    
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Fit k-nearest neighbors
    nbrs = NearestNeighbors(n_neighbors=k+1)  # +1 because point itself is included
    nbrs.fit(X_scaled)
    
    distances, indices = nbrs.kneighbors(X_scaled)
    
    # Average distance to k nearest neighbors (excluding self)
    avg_knn_distances = np.mean(distances[:, 1:], axis=1)
    
    # Determine threshold
    threshold = np.percentile(avg_knn_distances, threshold_percentile)
    
    result_df['knn_distance'] = avg_knn_distances
    result_df['is_outlier_knn'] = avg_knn_distances > threshold
    result_df['outlier_score_knn'] = avg_knn_distances / threshold
    
    return result_df


# =============================================================================
# DENSITY-BASED METHODS
# =============================================================================

def detect_outliers_lof(features_df, feature_cols, n_neighbors=20, contamination=0.1):
    """
    Detect outliers using Local Outlier Factor (LOF).
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        n_neighbors: Number of neighbors for density estimation
        contamination: Expected proportion of outliers
        
    Returns:
        DataFrame with LOF scores and outlier labels
    """
    result_df = features_df.copy()
    
    X = features_df[feature_cols].values
    
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Apply LOF
    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)
    outlier_labels = lof.fit_predict(X_scaled)
    lof_scores = -lof.negative_outlier_factor_  # Convert to positive scores
    
    result_df['lof_score'] = lof_scores
    result_df['is_outlier_lof'] = outlier_labels == -1
    result_df['outlier_score_lof'] = lof_scores
    
    return result_df


def detect_outliers_isolation_forest(features_df, feature_cols, contamination=0.1, random_state=42):
    """
    Detect outliers using Isolation Forest.
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        contamination: Expected proportion of outliers
        random_state: Random seed
        
    Returns:
        DataFrame with anomaly scores and outlier labels
    """
    result_df = features_df.copy()
    
    X = features_df[feature_cols].values
    
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Apply Isolation Forest
    iso_forest = IsolationForest(contamination=contamination, random_state=random_state)
    outlier_labels = iso_forest.fit_predict(X_scaled)
    anomaly_scores = -iso_forest.score_samples(X_scaled)  # Higher = more anomalous
    
    result_df['isolation_forest_score'] = anomaly_scores
    result_df['is_outlier_isolation_forest'] = outlier_labels == -1
    result_df['outlier_score_isolation_forest'] = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())
    
    return result_df


def detect_outliers_elliptic_envelope(features_df, feature_cols, contamination=0.1):
    """
    Detect outliers using Elliptic Envelope (assumes Gaussian distribution).
    
    Parameters:
        features_df: DataFrame with trajectory features
        feature_cols: List of feature column names to use
        contamination: Expected proportion of outliers
        
    Returns:
        DataFrame with outlier scores and labels
    """
    result_df = features_df.copy()
    
    X = features_df[feature_cols].values
    
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    try:
        # Apply Elliptic Envelope
        ee = EllipticEnvelope(contamination=contamination, random_state=42)
        outlier_labels = ee.fit_predict(X_scaled)
        
        # Get Mahalanobis distances
        mahal_distances = ee.mahalanobis(X_scaled)
        
        result_df['elliptic_envelope_distance'] = mahal_distances
        result_df['is_outlier_elliptic_envelope'] = outlier_labels == -1
        result_df['outlier_score_elliptic_envelope'] = mahal_distances / mahal_distances.max()
        
    except Exception:
        result_df['elliptic_envelope_distance'] = 0
        result_df['is_outlier_elliptic_envelope'] = False
        result_df['outlier_score_elliptic_envelope'] = 0
    
    return result_df


# =============================================================================
# VISUALIZATION FUNCTIONS
# =============================================================================

def plot_outliers_scatter(features_df, x_feature, y_feature, outlier_col, title):
    """Create scatter plot highlighting outliers."""
    fig = go.Figure()
    
    # Normal points
    normal = features_df[~features_df[outlier_col]]
    fig.add_trace(go.Scatter(
        x=normal[x_feature],
        y=normal[y_feature],
        mode='markers',
        name='Normal',
        marker=dict(size=8, color='blue', opacity=0.6),
        text=normal['trajectory_id'],
        hovertemplate='<b>%{text}</b><br>' + f'{x_feature}: %{{x:.2f}}<br>{y_feature}: %{{y:.2f}}<extra></extra>'
    ))
    
    # Outliers
    outliers = features_df[features_df[outlier_col]]
    if len(outliers) > 0:
        fig.add_trace(go.Scatter(
            x=outliers[x_feature],
            y=outliers[y_feature],
            mode='markers',
            name='Outlier',
            marker=dict(size=12, color='red', symbol='x', line=dict(width=2)),
            text=outliers['trajectory_id'],
            hovertemplate='<b>%{text}</b><br>' + f'{x_feature}: %{{x:.2f}}<br>{y_feature}: %{{y:.2f}}<extra></extra>'
        ))
    
    fig.update_layout(
        title=title,
        xaxis_title=x_feature.replace('_', ' ').title(),
        yaxis_title=y_feature.replace('_', ' ').title(),
        hovermode='closest',
        height=500
    )
    
    return fig


def plot_outlier_scores(features_df, score_col, title):
    """Create bar plot of outlier scores."""
    sorted_df = features_df.sort_values(score_col, ascending=False)
    
    # Convert score column name to is_outlier column name
    # e.g., 'outlier_score_zscore' -> 'is_outlier_zscore'
    outlier_col = score_col.replace('outlier_score_', 'is_outlier_')
    
    colors = ['red' if is_outlier else 'blue' 
              for is_outlier in sorted_df[outlier_col]]
    
    fig = go.Figure(data=[
        go.Bar(
            x=sorted_df['trajectory_id'],
            y=sorted_df[score_col],
            marker_color=colors,
            hovertemplate='<b>%{x}</b><br>Score: %{y:.2f}<extra></extra>'
        )
    ])
    
    fig.update_layout(
        title=title,
        xaxis_title='Trajectory',
        yaxis_title='Outlier Score',
        height=400,
        xaxis_tickangle=-45
    )
    
    return fig

def plot_boxplots(features_df, feature_cols):
    """Create box plots for multiple features to visualize outliers."""
    fig = go.Figure()
    
    for col in feature_cols:
        fig.add_trace(go.Box(
            y=features_df[col],
            name=col.replace('_', ' ').title(),
            boxmean='sd'
        ))
    
    fig.update_layout(
        title='Feature Distributions (Box Plots)',
        yaxis_title='Value',
        height=500,
        showlegend=True
    )
    
    return fig


def plot_convex_hull_layers(features_df, x_feature, y_feature):
    """Visualize convex hull layers."""
    fig = go.Figure()
    
    max_depth = int(features_df['convex_hull_depth'].max())
    colors = px.colors.sequential.Viridis
    
    for depth in range(1, max_depth + 1):
        layer_points = features_df[features_df['convex_hull_depth'] == depth]
        
        if len(layer_points) > 0:
            color_idx = min(int((depth - 1) / max_depth * (len(colors) - 1)), len(colors) - 1)
            
            fig.add_trace(go.Scatter(
                x=layer_points[x_feature],
                y=layer_points[y_feature],
                mode='markers',
                name=f'Depth {depth}',
                marker=dict(
                    size=10,
                    color=colors[color_idx],
                    line=dict(width=1, color='white')
                ),
                text=layer_points['trajectory_id'],
                hovertemplate='<b>%{text}</b><br>Depth: ' + str(depth) + '<br>' +
                              f'{x_feature}: %{{x:.2f}}<br>{y_feature}: %{{y:.2f}}<extra></extra>'
            ))
    
    fig.update_layout(
        title='Convex Hull Depth Layers',
        xaxis_title=x_feature.replace('_', ' ').title(),
        yaxis_title=y_feature.replace('_', ' ').title(),
        hovermode='closest',
        height=600
    )
    
    return fig


# =============================================================================
# MAIN RENDERING FUNCTION
# =============================================================================

def render_outlier_detection_section(data, selected_configs, selected_objects):
    """
    Main function to render the outlier detection section in Streamlit.
    
    Parameters:
        data: Full trajectory dataset
        selected_configs: List of selected configurations
        selected_objects: List of selected objects
    """
    st.header("üîç Outlier Detection")
    
    st.markdown("""
    **"An outlier is an observation which deviates so much from the other observations 
    as to arouse suspicions that it was generated by a different mechanism."** (Hawkins, 1980)
    
    Outlier detection is data mining's analogue to the "search for a needle in a haystack". 
    Discovered anomalies can either be attributed to errors or measurement noise, or they can 
    indicate unknown processes that need to be investigated further.
    
    This module implements **5 pedagogically clear detection methods** based on different theoretical approaches:
    - **Graphical**: Visual identification
    - **Statistical**: Based on distributions  
    - **Depth-Based**: Outliers at the border of data space
    - **Distance-Based**: Based on distances to neighbors
    - **Density-Based**: Based on local density differences
    """)
    
    # Filter data
    filtered_df = data[
        (data['config_source'].isin(selected_configs)) &
        (data['obj'].isin(selected_objects))
    ]
    
    if filtered_df.empty:
        st.warning("No data available for the selected configurations and objects.")
        return
    
    # Extract features for all trajectories
    st.subheader("1Ô∏è‚É£ Feature Extraction")
    
    with st.spinner("Extracting trajectory features..."):
        features_list = []
        
        for config in selected_configs:
            for obj in selected_objects:
                features = extract_trajectory_features(filtered_df, config, obj)
                if features is not None:
                    features_list.append(features)
        
        if not features_list:
            st.error("No valid trajectories found.")
            return
        
        features_df = pd.DataFrame(features_list)
    
    st.success(f"Extracted features from {len(features_df)} trajectories")
    
    # Display feature statistics
    with st.expander("üìä View Feature Statistics"):
        numeric_cols = features_df.select_dtypes(include=[np.number]).columns.tolist()
        st.dataframe(features_df[numeric_cols].describe())
    
    # Select features for outlier detection
    st.subheader("2Ô∏è‚É£ Select Features for Analysis")
    
    available_features = [
        'total_distance', 'duration', 'avg_speed', 'max_speed', 'std_speed',
        'avg_acceleration', 'max_acceleration', 'x_range', 'y_range',
        'sinuosity', 'total_turning_angle', 'x_std', 'y_std'
    ]
    
    selected_features = st.multiselect(
        "Select features to use for outlier detection:",
        available_features,
        default=['total_distance', 'avg_speed', 'duration', 'sinuosity']
    )
    
    if len(selected_features) < 1:
        st.warning("Please select at least 1 feature.")
        return
    
    # Select detection method
    st.subheader("3Ô∏è‚É£ Select Detection Method")
    
    st.info("""
    **Choose from 5 main categories** (aligned with theoretical framework):
    - **Graphical**: Visual identification using box plots
    - **Statistical**: Based on statistical distributions (Z-Score, IQR)
    - **Depth-Based**: Outliers at the border of data space (Convex Hull)
    - **Distance-Based**: Based on distances to neighbors (k-NN)
    - **Density-Based**: Based on local density differences (LOF)
    """)
    
    method = st.selectbox(
        "Choose outlier detection method:",
        [
            "Graphical: Box Plots",
            "Statistical: Z-Score",
            "Statistical: IQR (Interquartile Range)",
            "Depth-Based: Convex Hull Layers",
            "Distance-Based: k-Nearest Neighbors",
            "Density-Based: Local Outlier Factor (LOF)"
        ]
    )
    
    # Method-specific parameters
    st.subheader("4Ô∏è‚É£ Configure Parameters")
    
    col1, col2 = st.columns(2)
    
    if method == "Graphical: Box Plots":
        st.subheader("5Ô∏è‚É£ Box Plot Visualization")
        st.markdown("""
        **Graphical Method**: Visual identification of outliers using box plots.
        
        Box plots show the distribution of each feature and highlight potential outliers:
        - **Box** = Interquartile Range (IQR: Q1 to Q3) - contains middle 50% of data
        - **Line in box** = Median (Q2)
        - **Whiskers** = Extend to 1.5√óIQR from the quartiles
        - **Points beyond whiskers** = Potential outliers
        """)
        fig_box = plot_boxplots(features_df, selected_features)
        render_interactive_chart(st, fig_box, "Feature distributions showing outliers")
        return
    
    elif method == "Statistical: Z-Score":
        with col1:
            threshold = st.slider("Z-Score Threshold:", 1.0, 5.0, 3.0, 0.1,
                                help="Standard deviations from mean. Common: 3.0 (99.7% confidence)")
        
        with st.spinner("Detecting outliers..."):
            result_df = detect_outliers_zscore(features_df, selected_features, threshold)
            outlier_col = 'is_outlier_zscore'
            score_col = 'outlier_score_zscore'
        
        st.markdown(f"""
        **Statistical Method: Z-Score**
        
        Assumes data follows normal distribution. Points with |z-score| > {threshold} in any feature are outliers.
        - Z-score = (value - mean) / standard deviation
        - Threshold {threshold} ‚âà {(1 - 2*(1-0.9973))*100 if threshold==3.0 else 'varies'}% of data within bounds
        """)
    
    elif method == "Statistical: IQR (Interquartile Range)":
        with col1:
            multiplier = st.slider("IQR Multiplier:", 1.0, 3.0, 1.5, 0.1,
                                  help="Standard: 1.5 (mild outliers), 3.0 (extreme outliers)")
        
        with st.spinner("Detecting outliers..."):
            result_df = detect_outliers_iqr(features_df, selected_features, multiplier)
            outlier_col = 'is_outlier_iqr'
            score_col = 'outlier_score_iqr'
        
        st.markdown(f"""
        **Statistical Method: IQR (Interquartile Range)**
        
        Distribution-independent method using quartiles:
        - IQR = Q3 - Q1 (range containing middle 50% of data)
        - Lower bound = Q1 - {multiplier}√óIQR
        - Upper bound = Q3 + {multiplier}√óIQR
        - Points outside these bounds are outliers
        """)
    
    elif method == "Depth-Based: Convex Hull Layers":
        with col1:
            depth_threshold = st.slider("Depth Threshold:", 1, 5, 2, 1,
                                       help="Points in outer N layers are outliers. Lower = stricter")
        
        # Use only first 2 features for 2D convex hull
        hull_features = selected_features[:2]
        
        with st.spinner("Computing convex hull layers..."):
            result_df = detect_outliers_convex_hull(features_df, hull_features, depth_threshold)
            outlier_col = 'is_outlier_convex_hull'
            score_col = 'outlier_score_convex_hull'
        
        st.markdown(f"""
        **Depth-Based Method: Convex Hull Layers**
        
        Outliers are searched at the border of data space:
        - Points on outer convex hull = depth 1
        - After removing depth 1, next outer hull = depth 2
        - Points with depth ‚â§ {depth_threshold} are outliers
        - Using features: {', '.join(hull_features)}
        """)
        
        # Visualize convex hull layers
        st.subheader("5Ô∏è‚É£ Convex Hull Visualization")
        fig_hull = plot_convex_hull_layers(result_df, hull_features[0], hull_features[1])
        render_interactive_chart(st, fig_hull, "Convex Hull Depth Layers")
    
    elif method == "Distance-Based: k-Nearest Neighbors":
        with col1:
            k = st.slider("Number of Neighbors (k):", 3, 20, 5, 1,
                         help="How many nearest neighbors to consider")
        with col2:
            percentile = st.slider("Distance Percentile Threshold:", 80, 99, 95, 1,
                                  help="Points above this percentile are outliers")
        
        with st.spinner("Computing k-NN distances..."):
            result_df = detect_outliers_knn_distance(features_df, selected_features, k, percentile)
            outlier_col = 'is_outlier_knn'
            score_col = 'outlier_score_knn'
        
        st.markdown(f"""
        **Distance-Based Method: k-Nearest Neighbors**
        
        Outliers are far from their neighbors:
        - For each point, find {k} nearest neighbors
        - Calculate average distance to these neighbors
        - Points with distance above {percentile}th percentile are outliers
        - Assumption: Normal points cluster together, outliers are isolated
        """)
    
    elif method == "Density-Based: Local Outlier Factor (LOF)":
        with col1:
            n_neighbors = st.slider("Number of Neighbors:", 5, 50, 20, 5,
                                   help="How many neighbors to consider for density")
        with col2:
            contamination = st.slider("Expected Outlier Proportion:", 0.01, 0.5, 0.1, 0.01,
                                     help="Estimated fraction of outliers in data")
        
        with st.spinner("Computing LOF scores..."):
            result_df = detect_outliers_lof(features_df, selected_features, n_neighbors, contamination)
            outlier_col = 'is_outlier_lof'
            score_col = 'outlier_score_lof'
        
        st.markdown(f"""
        **Density-Based Method: Local Outlier Factor**
        
        Compares local density around each point to neighbors' densities:
        - Normal points: surrounded by similar density neighbors (LOF ‚âà 1)
        - Outliers: in low-density regions compared to neighbors (LOF > 1)
        - Using {n_neighbors} neighbors to estimate local density
        - Expecting ‚âà{contamination*100:.1f}% outliers
        """)
    
    # Display results (for non-graphical methods)
    st.subheader("5Ô∏è‚É£ Detection Results")
    
    n_outliers = result_df[outlier_col].sum()
    n_total = len(result_df)
    outlier_pct = (n_outliers / n_total * 100) if n_total > 0 else 0
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Total Trajectories", n_total)
    col2.metric("Outliers Detected", n_outliers)
    col3.metric("Outlier Percentage", f"{outlier_pct:.1f}%")
    
    # Outlier list
    if n_outliers > 0:
        st.subheader("üìã Detected Outliers")
        outliers_df = result_df[result_df[outlier_col]][['trajectory_id', score_col] + selected_features]
        outliers_df = outliers_df.sort_values(score_col, ascending=False)
        st.dataframe(outliers_df.style.format({score_col: '{:.3f}'}))
    
    # Visualizations
    st.subheader("6Ô∏è‚É£ Visualizations")
    
    # For methods other than Convex Hull, offer MDS projection when data is high-dimensional
    if method != "Depth-Based: Convex Hull Layers" and len(selected_features) >= 3:
        st.markdown(f"""
        **üí° Your data has {len(selected_features)} dimensions ({', '.join(selected_features)})**
        
        Since the original feature space is {len(selected_features)}-dimensional, we can use 
        **MDS (Multidimensional Scaling)** to project it to 2D or 3D for visualization while 
        preserving distances between trajectories.
        """)
        
        mds_dims = st.radio(
            "MDS Projection Dimensions:", 
            [2, 3], 
            horizontal=True,
            help="Project high-dimensional data to 2D or 3D for visualization"
        )
        
        with st.spinner(f"Computing MDS {mds_dims}D projection..."):
            from sklearn.manifold import MDS
            from sklearn.preprocessing import StandardScaler
            
            # Standardize features for MDS
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(result_df[selected_features])
            
            # Apply MDS
            mds = MDS(n_components=mds_dims, random_state=42)
            mds_coords = mds.fit_transform(features_scaled)
            
            # Create MDS visualization
            if mds_dims == 2:
                fig_mds = go.Figure()
                
                # Normal points
                normal_mask = ~result_df[outlier_col]
                fig_mds.add_trace(go.Scatter(
                    x=mds_coords[normal_mask, 0],
                    y=mds_coords[normal_mask, 1],
                    mode='markers',
                    name='Normal',
                    marker=dict(size=8, color='lightblue', line=dict(width=1, color='white')),
                    text=result_df[normal_mask]['trajectory_id'],
                    hovertemplate='<b>%{text}</b><br>MDS-X: %{x:.2f}<br>MDS-Y: %{y:.2f}<extra></extra>'
                ))
                
                # Outliers
                outlier_mask = result_df[outlier_col]
                fig_mds.add_trace(go.Scatter(
                    x=mds_coords[outlier_mask, 0],
                    y=mds_coords[outlier_mask, 1],
                    mode='markers',
                    name='Outlier',
                    marker=dict(size=12, color='red', symbol='x', line=dict(width=2, color='darkred')),
                    text=result_df[outlier_mask]['trajectory_id'],
                    hovertemplate='<b>%{text}</b><br>MDS-X: %{x:.2f}<br>MDS-Y: %{y:.2f}<extra></extra>'
                ))
                
                fig_mds.update_layout(
                    title=f"MDS 2D Projection: {method}",
                    xaxis_title="MDS Dimension 1",
                    yaxis_title="MDS Dimension 2",
                    hovermode='closest',
                    height=600
                )
                
            else:  # 3D
                fig_mds = go.Figure()
                
                # Normal points
                normal_mask = ~result_df[outlier_col]
                fig_mds.add_trace(go.Scatter3d(
                    x=mds_coords[normal_mask, 0],
                    y=mds_coords[normal_mask, 1],
                    z=mds_coords[normal_mask, 2],
                    mode='markers',
                    name='Normal',
                    marker=dict(size=5, color='lightblue', line=dict(width=0.5, color='white')),
                    text=result_df[normal_mask]['trajectory_id'],
                    hovertemplate='<b>%{text}</b><br>MDS-X: %{x:.2f}<br>MDS-Y: %{y:.2f}<br>MDS-Z: %{z:.2f}<extra></extra>'
                ))
                
                # Outliers
                outlier_mask = result_df[outlier_col]
                fig_mds.add_trace(go.Scatter3d(
                    x=mds_coords[outlier_mask, 0],
                    y=mds_coords[outlier_mask, 1],
                    z=mds_coords[outlier_mask, 2],
                    mode='markers',
                    name='Outlier',
                    marker=dict(size=8, color='red', symbol='x', line=dict(width=1, color='darkred')),
                    text=result_df[outlier_mask]['trajectory_id'],
                    hovertemplate='<b>%{text}</b><br>MDS-X: %{x:.2f}<br>MDS-Y: %{y:.2f}<br>MDS-Z: %{z:.2f}<extra></extra>'
                ))
                
                fig_mds.update_layout(
                    title=f"MDS 3D Projection: {method}",
                    scene=dict(
                        xaxis_title="MDS Dimension 1",
                        yaxis_title="MDS Dimension 2",
                        zaxis_title="MDS Dimension 3"
                    ),
                    hovermode='closest',
                    height=700
                )
            
            render_interactive_chart(st, fig_mds, f"MDS {mds_dims}D Projection showing outliers")
            
            st.caption(f"""
            **MDS Projection**: Reduces {len(selected_features)}D data to {mds_dims}D while preserving pairwise distances. 
            Points close together in this plot have similar feature values in the original {len(selected_features)}-dimensional space.
            """)
    
    # Original 2D scatter plot (for direct feature comparison)
    if len(selected_features) >= 2:
        st.markdown("---")
        st.markdown("**Feature-to-Feature Scatter Plot** (direct comparison of any 2 features)")
        
        viz_col1, viz_col2 = st.columns(2)
        
        with viz_col1:
            x_feat = st.selectbox("X-axis feature:", selected_features, index=0)
        with viz_col2:
            y_feat = st.selectbox("Y-axis feature:", selected_features, index=min(1, len(selected_features)-1))
        
        fig_scatter = plot_outliers_scatter(result_df, x_feat, y_feat, outlier_col, 
                                           f"Outlier Detection: {method}")
        render_interactive_chart(st, fig_scatter, "Direct feature comparison")
    
    # Trajectory Visualization on Tennis Court
    st.markdown("---")
    st.markdown("**üéæ Trajectory Visualization on Tennis Court**")
    st.markdown("See the actual movement patterns of outlier vs normal trajectories")
    
    if n_outliers > 0:
        # Get trajectory IDs for outliers and normal trajectories
        outlier_rows = result_df[result_df[outlier_col]].copy()
        normal_rows = result_df[~result_df[outlier_col]].copy()
        
        # Let user select which trajectories to visualize
        viz_mode = st.radio(
            "Visualization mode:",
            ["Outliers Only", "Outliers + Sample of Normal", "Compare Selected"],
            horizontal=True
        )
        
        trajectories_to_plot = []
        colors = []
        labels = []
        
        if viz_mode == "Outliers Only":
            # Show all outliers
            if len(outlier_rows) == 1:
                max_outliers = 1
                st.info(f"Showing the single outlier detected")
            else:
                max_outliers = st.slider("Max outliers to show:", 1, min(20, len(outlier_rows)), min(10, len(outlier_rows)))
            
            for i, (idx, row) in enumerate(outlier_rows.head(max_outliers).iterrows()):
                config = row['config']
                obj = row['object']
                traj_id = row['trajectory_id']
                
                # Find all points for this trajectory in filtered_df
                traj_data = filtered_df[
                    (filtered_df['config_source'] == config) &
                    (filtered_df['obj'] == obj)
                ].copy()
                
                if not traj_data.empty:
                    trajectories_to_plot.append(traj_data)
                    colors.append('red')
                    labels.append(f"OUTLIER: {traj_id}")
        
        elif viz_mode == "Outliers + Sample of Normal":
            # Show outliers + random sample of normal
            if len(outlier_rows) == 1:
                max_outliers = 1
            else:
                max_outliers = st.slider("Max outliers to show:", 1, min(10, len(outlier_rows)), min(5, len(outlier_rows)))
            
            if len(normal_rows) == 1:
                max_normal = 1
            else:
                max_normal = st.slider("Max normal trajectories to show:", 1, min(10, len(normal_rows)), min(5, len(normal_rows)))
            
            # Add outliers
            for i, (idx, row) in enumerate(outlier_rows.head(max_outliers).iterrows()):
                config = row['config']
                obj = row['object']
                traj_id = row['trajectory_id']
                
                traj_data = filtered_df[
                    (filtered_df['config_source'] == config) &
                    (filtered_df['obj'] == obj)
                ].copy()
                
                if not traj_data.empty:
                    trajectories_to_plot.append(traj_data)
                    colors.append('red')
                    labels.append(f"OUTLIER: {traj_id}")
            
            # Add random sample of normal
            sample_normal_rows = normal_rows.sample(min(max_normal, len(normal_rows)))
            
            for idx, row in sample_normal_rows.iterrows():
                config = row['config']
                obj = row['object']
                traj_id = row['trajectory_id']
                
                traj_data = filtered_df[
                    (filtered_df['config_source'] == config) &
                    (filtered_df['obj'] == obj)
                ].copy()
                
                if not traj_data.empty:
                    trajectories_to_plot.append(traj_data)
                    colors.append('lightblue')
                    labels.append(f"Normal: {traj_id}")
        
        else:  # Compare Selected
            st.markdown("**Select specific trajectories to compare:**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Outlier Trajectories:**")
                selected_outlier_ids = st.multiselect(
                    "Select outliers:",
                    outlier_rows['trajectory_id'].tolist(),
                    default=outlier_rows['trajectory_id'].tolist()[:min(3, len(outlier_rows))]
                )
            
            with col2:
                st.markdown("**Normal Trajectories:**")
                selected_normal_ids = st.multiselect(
                    "Select normal:",
                    normal_rows['trajectory_id'].tolist(),
                    default=normal_rows['trajectory_id'].tolist()[:min(3, len(normal_rows))]
                )
            
            # Add selected outliers
            for traj_id in selected_outlier_ids:
                row = outlier_rows[outlier_rows['trajectory_id'] == traj_id].iloc[0]
                config = row['config']
                obj = row['object']
                
                traj_data = filtered_df[
                    (filtered_df['config_source'] == config) &
                    (filtered_df['obj'] == obj)
                ].copy()
                
                if not traj_data.empty:
                    trajectories_to_plot.append(traj_data)
                    colors.append('red')
                    labels.append(f"OUTLIER: {traj_id}")
            
            # Add selected normal
            for traj_id in selected_normal_ids:
                row = normal_rows[normal_rows['trajectory_id'] == traj_id].iloc[0]
                config = row['config']
                obj = row['object']
                
                traj_data = filtered_df[
                    (filtered_df['config_source'] == config) &
                    (filtered_df['obj'] == obj)
                ].copy()
                
                if not traj_data.empty:
                    trajectories_to_plot.append(traj_data)
                    colors.append('lightblue')
                    labels.append(f"Normal: {traj_id}")
        
        # Plot trajectories on tennis court
        if trajectories_to_plot:
            import sys
            import os
            # Add parent directory to path to import streamlit_visualization
            parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            if parent_dir not in sys.path:
                sys.path.insert(0, parent_dir)
            
            from streamlit_visualization import create_pitch_figure
            
            fig_court = create_pitch_figure('Tennis')
            
            # Add each trajectory
            for traj_data, color, label in zip(trajectories_to_plot, colors, labels):
                # Sort by timestamp
                if 'tst' in traj_data.columns:
                    traj_data = traj_data.sort_values('tst')
                
                # Add trajectory line
                fig_court.add_trace(go.Scatter(
                    x=traj_data['x'],
                    y=traj_data['y'],
                    mode='lines+markers',
                    name=label,
                    line=dict(color=color, width=2),
                    marker=dict(size=4, color=color),
                    hovertemplate=f'<b>{label}</b><br>X: %{{x:.2f}}<br>Y: %{{y:.2f}}<extra></extra>'
                ))
                
                # Mark start and end
                fig_court.add_trace(go.Scatter(
                    x=[traj_data['x'].iloc[0]],
                    y=[traj_data['y'].iloc[0]],
                    mode='markers',
                    name=f'{label} (start)',
                    marker=dict(size=10, color=color, symbol='circle', line=dict(width=2, color='white')),
                    showlegend=False,
                    hovertemplate=f'<b>{label} START</b><extra></extra>'
                ))
                
                fig_court.add_trace(go.Scatter(
                    x=[traj_data['x'].iloc[-1]],
                    y=[traj_data['y'].iloc[-1]],
                    mode='markers',
                    name=f'{label} (end)',
                    marker=dict(size=10, color=color, symbol='square', line=dict(width=2, color='white')),
                    showlegend=False,
                    hovertemplate=f'<b>{label} END</b><extra></extra>'
                ))
            
            fig_court.update_layout(
                title=f"Trajectory Visualization: {method}",
                height=600,
                showlegend=True,
                legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
            )
            
            render_interactive_chart(st, fig_court, "Trajectories on tennis court")
            
            st.caption("""
            **Legend**: üî¥ Red = Outlier trajectories | üîµ Light Blue = Normal trajectories | 
            ‚óè Circle = Start | ‚ñ† Square = End
            """)
        else:
            st.info("Select trajectories to visualize")
    else:
        st.info("No outliers detected - cannot show trajectory comparison")
    
    # Score distribution
    if score_col in result_df.columns:
        st.markdown("---")
        fig_scores = plot_outlier_scores(result_df, score_col, f"Outlier Scores: {method}")
        render_interactive_chart(st, fig_scores, "Outlier scores")
    
    # Download results
    st.subheader("7Ô∏è‚É£ Export Results")
    
    csv = result_df.to_csv(index=False)
    st.download_button(
        label="üì• Download Results as CSV",
        data=csv,
        file_name=f"outlier_detection_{method.replace(':', '').replace(' ', '_').lower()}.csv",
        mime="text/csv"
    )
